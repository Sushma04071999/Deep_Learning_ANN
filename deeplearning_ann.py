# -*- coding: utf-8 -*-
"""Deeplearning_ANN.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sKMzWWzfr3g_ZHKpuybKUR-7Hmv0flSO
"""

import tensorflow as tf

#Check the version of TensorFlow you are using
print(tf.__version__)
print(tf.config.list_physical_devices('GPU'))

import tensorflow as tf

#Check the version of TensorFlow you are using
print(tf.__version__)

##import some basic libraries
import numpy as np
import matplotlib.pyplot as plt
import pandas as pd

dataset= pd.read_csv("Churn_Modelling.csv")

dataset.head()

#divide the dataset into independent and dependent features

X= dataset.iloc[:,3:13]
y= dataset.iloc[:,13]

X.head()
y.head()

#Feature Engineering
geography= pd.get_dummies(X["Geography"],drop_first=True,dtype=int)
gender = pd.get_dummies(X["Gender"],drop_first=True,dtype=int)

geography
gender

X=X.drop(["Geography","Gender"],axis=1)

X

X=pd.concat([X,geography,gender],axis=1)

#splitting the dataset into Training set and Test set

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test = train_test_split(X,y,test_size= 0.2,random_state=0)

#part2 crete the ANN

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras.layers import ReLU,PReLU,ELU,LeakyReLU
from tensorflow.keras.layers import  Dropout

# lets intialize the ANN
classifier= Sequential()

# Adding the input layer
classifier.add(Dense(units=11,activation="relu"))

# Adding the first hidden layer (here i considering the 7 units or nurons)
classifier.add(Dense(units=7,activation="relu"))
classifier.add(Dropout(0.2))

# Adding the second hidden layer (here i considering the 6 units or nurons)
classifier.add(Dense(units=6,activation="relu"))
classifier.add(Dropout(0.3))

# Adding the output layer
classifier.add(Dense(1,activation="sigmoid"))

import tensorflow
opt = tensorflow.keras.optimizers.Adam(learning_rate= 0.01)

#Compiling the neural network

#classifier.compile(optimizer='adam',loss="binary_crossentropy",metrics=["accuracy"])
classifier.compile(optimizer=opt ,loss="binary_crossentropy",metrics=["accuracy"])

#Early stopping
import tensorflow as tf

early_stopping= tf.keras.callbacks.EarlyStopping(
    monitor="val_loss",
    min_delta=0.001,
    patience=20,
    verbose=1,
    mode="auto",
    baseline=None,
    restore_best_weights=False,
    start_from_epoch=0,
)

# train the beural network
model_history= classifier.fit(X_train,y_train,validation_split=0.33,batch_size =10,epochs =1000,callbacks=early_stopping)

model_history.history.keys()

#summarize the history for accuracy

plt.plot(model_history.history["accuracy"])
plt.plot(model_history.history["val_accuracy"])
plt.title("model accuracy")
plt.ylabel("accuracy")
plt.xlabel("epoch")
plt.legend(["train","test"],loc="upper left")
plt.show()

plt.plot(model_history.history["loss"])
plt.plot(model_history.history["val_accuracy"])
plt.title("model accuracy")
plt.ylabel("accuracy")
plt.xlabel("epoch")
plt.legend(["train","test"],loc="upper left")
plt.show()

# part 3  - making the predictions and evaluating the model

# predicting the test set results

y_pred =classifier.predict(X_test)
y_pred =(y_pred >= 0.5)

#confusion matrix

from sklearn.metrics import confusion_matrix
cm= confusion_matrix(y_test,y_pred)
cm

#calculate accuracy

from sklearn.metrics import accuracy_score
score = accuracy_score(y_pred,y_test)

score

#get the weights

classifier.get_weights()

